{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm tqdm scikit-learn joblib --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"Progress\")"
      ],
      "metadata": {
        "id": "L7n6DLN40msb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_columns = ['sample_id', 'catalog_content', 'image_link', 'price']\n",
        "df_train = pd.read_csv(\"train.csv\", names=train_columns, engine='python', on_bad_lines='skip')\n",
        "\n",
        "print(f\"✅ Train rows loaded: {len(df_train)}\")\n",
        "\n",
        "# Fill missing prices\n",
        "df_train['price'] = pd.to_numeric(df_train['price'], errors='coerce')\n",
        "df_train['price'] = df_train['price'].fillna(df_train['price'].mean())\n"
      ],
      "metadata": {
        "id": "-W-wZ18Qy3wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0659fd-092e-410c-aa8a-b0be0cd0be09"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train rows loaded: 75001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Lowercase, remove unwanted symbols, keep meaningful text.\"\"\"\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "esR08uY59whO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_units = {\n",
        "    'gram': ['g','gm','grams'],\n",
        "    'kilogram': ['kg','kgs','kilogram','kilograms'],\n",
        "    'milliliter': ['ml','milliliter','milliliters'],\n",
        "    'liter': ['l','ltr','liter','liters'],\n",
        "    'ounce': ['oz','ounce','ounces'],\n",
        "    'pound': ['lb','lbs','pound','pounds']\n",
        "}\n",
        "\n",
        "def extract_quantity(text):\n",
        "    text = str(text).lower()\n",
        "    match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(pack|packs|pcs|pieces|bottle|can|jar|bunch|box|set|sets|dozen)?', text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    nums = re.findall(r'\\b\\d+(?:\\.\\d+)?\\b', text)\n",
        "    return float(nums[0]) if nums else 1.0\n",
        "\n",
        "def extract_weight(text):\n",
        "    \"\"\"Handle compound weights like '1 kg x 2 pack'\"\"\"\n",
        "    text = str(text).lower()\n",
        "    quantity = 1.0\n",
        "    # handle 'x' pattern for multiple packs\n",
        "    x_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(kg|g|ml|l|oz|lb)s?\\s*(?:x|×)\\s*(\\d+)', text)\n",
        "    if x_match:\n",
        "        val, unit, mult = x_match.groups()\n",
        "        val = float(val)\n",
        "        mult = float(mult)\n",
        "        if unit.startswith('kg'): val *= 1000\n",
        "        elif unit.startswith('l'): val *= 1000\n",
        "        elif unit.startswith('lb'): val *= 453.592\n",
        "        elif unit.startswith('oz'): val *= 28.3495\n",
        "        return round(val * mult,2)\n",
        "\n",
        "    # fallback: simple weight extraction\n",
        "    total_weight = 0.0\n",
        "    for unit, variants in weight_units.items():\n",
        "        for v in variants:\n",
        "            matches = re.findall(r'(\\d+(?:\\.\\d+)?)\\s*' + re.escape(v), text)\n",
        "            for val in matches:\n",
        "                val = float(val)\n",
        "                if unit == 'kilogram': val *= 1000\n",
        "                elif unit == 'liter': val *= 1000\n",
        "                elif unit == 'pound': val *= 453.592\n",
        "                elif unit == 'ounce': val *= 28.3495\n",
        "                total_weight += val\n",
        "    if total_weight == 0: total_weight = 250\n",
        "    return round(total_weight,2)\n"
      ],
      "metadata": {
        "id": "OYiktlJPTEyU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6eda1ad"
      },
      "source": [
        "def extract_brand(text):\n",
        "    words = re.findall(r'\\b[A-Z][a-zA-Z]+\\b', str(text))\n",
        "    generic_words = {'Pack','Set','Box','New','Best','The'}\n",
        "    for w in words:\n",
        "        if w not in generic_words:\n",
        "            return w\n",
        "    return \"Unknown\"\n",
        "\n",
        "def detect_category(text):\n",
        "    text = str(text).lower()\n",
        "    categories = {\n",
        "        'electronics': ['phone','laptop','charger','headphone','camera','battery','speaker','tablet','cable'],\n",
        "        'clothing': ['shirt','pants','dress','jacket','jeans','skirt','blouse','t-shirt'],\n",
        "        'grocery': ['food','snack','rice','oil','juice','drink','spice','vegetable','fruit'],\n",
        "        'home_kitchen': ['kitchen','appliance','utensil','furniture','bed','decor','pillow','towel'],\n",
        "        'beauty_personal': ['cosmetic','makeup','skin','hair','shampoo','lotion','perfume','soap']\n",
        "    }\n",
        "    for cat, keys in categories.items():\n",
        "        if any(k in text for k in keys):\n",
        "            return cat\n",
        "    return 'other'\n",
        "\n",
        "def detect_flags(text):\n",
        "    t = str(text).lower()\n",
        "    return pd.Series({\n",
        "        'is_premium': int(any(k in t for k in ['premium','luxury','exclusive'])),\n",
        "        'is_organic': int(any(k in t for k in ['organic','natural','eco'])),\n",
        "        'is_discount': int(any(k in t for k in ['sale','discount','offer','deal'])),\n",
        "        'has_warranty': int(any(k in t for k in ['warranty','guarantee'])),\n",
        "        'is_new': int(any(k in t for k in ['new','latest','2023','2024']))\n",
        "    })\n",
        "\n",
        "def detect_color(text):\n",
        "    colors = ['red','blue','green','black','white','yellow','pink','orange','brown','silver','gold','purple','grey']\n",
        "    t = str(text).lower()\n",
        "    for c in colors:\n",
        "        if c in t: return c\n",
        "    return 'unknown'\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75a3de9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508f9e32-8f2c-472e-c8cc-3c1978cc0334"
      },
      "source": [
        "df_train['quantity'] = df_train['catalog_content'].progress_apply(extract_quantity)\n",
        "df_train['total_weight_g'] = df_train['catalog_content'].progress_apply(extract_weight)\n",
        "df_train['brand'] = df_train['catalog_content'].progress_apply(extract_brand)\n",
        "df_train['category'] = df_train['catalog_content'].progress_apply(detect_category)\n",
        "flags_df = df_train['catalog_content'].progress_apply(detect_flags)\n",
        "df_train = pd.concat([df_train, flags_df], axis=1)\n",
        "df_train['dominant_color'] = df_train['catalog_content'].progress_apply(detect_color)\n",
        "df_train['clean_text'] = df_train['catalog_content'].progress_apply(clean_text)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 75001/75001 [00:03<00:00, 22099.65it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [01:08<00:00, 1095.22it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [00:02<00:00, 30119.87it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [00:02<00:00, 26521.43it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [00:21<00:00, 3475.09it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [00:00<00:00, 94890.78it/s]\n",
            "Progress: 100%|██████████| 75001/75001 [00:09<00:00, 8061.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Compute embeddings\n",
        "df_train['text_embedding'] = df_train['clean_text'].progress_apply(lambda x: sbert_model.encode(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohJ6UMFKVflN",
        "outputId": "ab349f42-a598-4e8b-e8d0-2ff15b462b25"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 75001/75001 [1:43:30<00:00, 12.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['quantity','total_weight_g']\n",
        "categorical_features = ['brand','category','dominant_color','is_premium','is_organic','is_discount','has_warranty','is_new']\n",
        "\n",
        "X_numeric = df_train[numeric_features].values\n",
        "X_categorical = pd.get_dummies(df_train[categorical_features])\n",
        "X_text = np.stack(df_train['text_embedding'].values)\n",
        "\n",
        "# Concatenate all features\n",
        "X = np.hstack([X_numeric, X_categorical.values, X_text])\n",
        "y = np.log1p(df_train['price'])\n"
      ],
      "metadata": {
        "id": "ZjzaAABAVfn3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=1800,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=50fir ,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    reg_alpha=0.2,\n",
        "    reg_lambda=0.4,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgb_model.fit(X_train, y_train)\n",
        "print(\"✅ Model trained with SentenceTransformer embeddings!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLqbZlmGVfqj",
        "outputId": "772f9452-c874-406c-961e-fb94d6e09161"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained with SentenceTransformer embeddings!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    diff = np.abs(y_pred - y_true) / np.where(denom==0, 1, denom)\n",
        "    return np.mean(diff) * 100\n",
        "\n",
        "y_val_pred = np.expm1(lgb_model.predict(X_val))\n",
        "y_val_true = np.expm1(y_val)\n",
        "score = smape(y_val_true, y_val_pred)\n",
        "print(f\"✅ Validation SMAPE: {score:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waz5rklhVftR",
        "outputId": "3811fbaf-37ab-4213-950a-611f358a9653"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validation SMAPE: 56.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"test.csv\", names=['sample_id','catalog_content','image_link'], engine='python', on_bad_lines='skip')\n",
        "df_test = df_test.dropna(subset=['catalog_content']).reset_index(drop=True)\n",
        "\n",
        "df_test['quantity'] = df_test['catalog_content'].progress_apply(extract_quantity)\n",
        "df_test['total_weight_g'] = df_test['catalog_content'].progress_apply(extract_weight)\n",
        "df_test['brand'] = df_test['catalog_content'].progress_apply(extract_brand)\n",
        "df_test['category'] = df_test['catalog_content'].progress_apply(detect_category)\n",
        "flags_test = df_test['catalog_content'].progress_apply(detect_flags)\n",
        "df_test = pd.concat([df_test, flags_test], axis=1)\n",
        "df_test['dominant_color'] = df_test['catalog_content'].progress_apply(detect_color)\n",
        "df_test['clean_text'] = df_test['catalog_content'].progress_apply(clean_text)\n",
        "df_test['text_embedding'] = df_test['clean_text'].progress_apply(lambda x: sbert_model.encode(x))\n"
      ],
      "metadata": {
        "id": "NeyRPT2MVfvm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_numeric = df_test[numeric_features].values\n",
        "X_test_categorical = pd.get_dummies(df_test[categorical_features])\n",
        "\n",
        "# Ensure same columns as train\n",
        "X_test_categorical = X_test_categorical.reindex(columns=X_categorical.columns, fill_value=0)\n",
        "X_test_text = np.stack(df_test['text_embedding'].values)\n",
        "\n",
        "X_test = np.hstack([X_test_numeric, X_test_categorical.values, X_test_text])\n",
        "\n",
        "y_test_pred = np.expm1(lgb_model.predict(X_test))\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'sample_id': df_test['sample_id'],\n",
        "    'price': y_test_pred\n",
        "})\n",
        "submission.to_csv(\"test_predictions_sbert.csv\", index=False)\n",
        "print(\"✅ Test predictions saved to 'test_predictions_sbert.csv'\")\n"
      ],
      "metadata": {
        "id": "vsfnnFfqVf1E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZu_l5yQVf4l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVRgYy2CMN51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvG4S_7K0lSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}